rm(list=ls())  #clear workspace
opar.org <- par(no.readonly=TRUE)
#home <- "c:/Users/tpiechowiak/R code/R-code/Lektion 7/"
home <- "c:/Users/tobiasp/Documents/Big Data/R-code/Lektion 7/"
setwd(home)
#loc <-"c:/Users/tpiechowiak/Documents/R/win-library/3.3/"
loc <-"c:/Users/tobiasp/Documents/Big Data/R_packages/"
rm(list=ls())  #clear workspace
opar.org <- par(no.readonly=TRUE)
home <- "c:/Users/tpiechowiak/R code/R-code/Lektion 7/"
#home <- "c:/Users/tobiasp/Documents/Big Data/R-code/Lektion 7/"
setwd(home)
loc <-"c:/Users/tpiechowiak/Documents/R/win-library/3.3/"
#loc <-"c:/Users/tobiasp/Documents/Big Data/R_packages/"
library("proxy",lib=loc)
library("randomForest",lib=loc)
library("e1071",lib=loc)
library("ISLR",lib=loc)
library("tree",lib=loc)
library("MASS",lib=loc)
library("rattle",lib=loc)
library("kernlab",lib=loc)
library("dtw",lib=loc)
library("class",lib=loc)
#prepare data
loc1 <- "http://archive.ics.uci.edu/ml/machine-learning-databases/"
ds  <- "breast-cancer-wisconsin/breast-cancer-wisconsin.data"
url <- paste(loc1, ds, sep="")
#
breast <- read.table(url, sep=",", header=FALSE, na.strings="?")
str(breast)
names(breast) <- c("ID", "clumpThickness", "sizeUniformity",
"shapeUniformity", "maginalAdhesion",
"singleEpithelialCellSize", "bareNuclei",
"blandChromatin", "normalNucleoli", "mitosis", "class")
df <- breast[-1]   # Remove the first column (identity).
df$class <- factor(df$class, levels=c(2,4),
labels=c("benign", "malignant"))
#prepare training data
train <- sample(nrow(df), 0.7*nrow(df))   # Use 70% of dataset for training.
df.train <- df[train,]        # Form training set.
df.validate <- df[-train,]    # Use the rest of dataset (30%) for validation.
table(df.train$class)
table(df.validate$class)
rr <- performance <- function(table, n=2){
if(!all(dim(table) == c(2,2)))
stop("Must be a 2 x 2 table")
tn = table[1,1]
fp = table[1,2]
fn = table[2,1]
tp = table[2,2]
sensitivity = tp/(tp+fn)
specificity = tn/(tn+fp)
ppp = tp/(tp+fp)
npp = tn/(tn+fn)
hitrate = (tp+tn)/(tp+tn+fp+fn)
#result <- paste("Sensitivity = ", round(sensitivity, n) ,
#               "\nSpecificity = ", round(specificity, n),
#              "\nPositive Predictive Value = ", round(ppp, n),
#             "\nNegative Predictive Value = ", round(npp, n),
#            "\nAccuracy = ", round(hitrate, n), "\n", sep="")
#cat(result)
return(hitrate)
}
err <- performance <- function(table, n=2){
if(!all(dim(table) == c(2,2)))
stop("Must be a 2 x 2 table")
tn = table[1,1]
fp = table[1,2]
fn = table[2,1]
tp = table[2,2]
sensitivity = tp/(tp+fn)
specificity = tn/(tn+fp)
ppp = tp/(tp+fp)
npp = tn/(tn+fn)
hitrate = (tp+tn)/(tp+tn+fp+fn)
#result <- paste("Sensitivity = ", round(sensitivity, n) ,
#               "\nSpecificity = ", round(specificity, n),
#              "\nPositive Predictive Value = ", round(ppp, n),
#             "\nNegative Predictive Value = ", round(npp, n),
#            "\nAccuracy = ", round(hitrate, n), "\n", sep="")
#cat(result)
return(hitrate)
}
set.seed(1234)
gamma.value <- c(1/50,1/9,2) #possible values of gamma
rname <- c("gamma=1/50","gamma=1/9","gamma=2")
cname <- c("value")
err.classification.svm <- matrix(0,nrow=length(gamma.value),ncol = 1,
dimnames=list(rname,cname))
for(i in 1:3){
fit.svm <- svm(class~., data=df.train,gamma=gamma.value[i],
kernel="radial basis")
#gamma default:  1/(data dimension), in this case 1/9
fit.svm
svm.pred <- predict(fit.svm, na.omit(df.validate))
svm.perf <- table(na.omit(df.validate)$class,
svm.pred, dnn=c("Actual", "Predicted"))
err.classification.svm[i] <- (1 - performance(svm.perf))*100
}
# Save for later performance comparison:
save(err.classification.svm, file="perf_svm.perf")
#
#
?svm
#7.2
#support vector machine
set.seed(1234)
gamma.value <- c(1/50,1/9,2) #possible values of gamma
rname <- c("gamma=1/50","gamma=1/9","gamma=2")
cname <- c("value")
err.classification.svm <- matrix(0,nrow=length(gamma.value),ncol = 1,
dimnames=list(rname,cname))
for(i in 1:3){
fit.svm <- svm(class~., data=df.train,gamma=gamma.value[i],
kernel="radial")
#gamma default:  1/(data dimension), in this case 1/9
fit.svm
svm.pred <- predict(fit.svm, na.omit(df.validate))
svm.perf <- table(na.omit(df.validate)$class,
svm.pred, dnn=c("Actual", "Predicted"))
err.classification.svm[i] <- (1 - performance(svm.perf))*100
}
# Save for later performance comparison:
save(err.classification.svm, file="perf_svm.perf")
#7.2
#support vector machine
set.seed(1234)
gamma.value <- c(1/50,1/9,2) #possible values of gamma
rname <- c("gamma=1/50","gamma=1/9","gamma=2")
cname <- c("value")
err.classification.svm <- matrix(0,nrow=length(gamma.value),ncol = 1,
dimnames=list(rname,cname))
for(i in 1:3){
fit.svm <- svm(class~., data=df.train,gamma=gamma.value[i],
kernel="radial")
#gamma default:  1/(data dimension), in this case 1/9
fit.svm
svm.pred <- predict(fit.svm, na.omit(df.validate))
svm.perf <- table(na.omit(df.validate)$class,
svm.pred, dnn=c("Actual", "Predicted"))
err.classification.svm[i] <- (1 - performance(svm.perf))*100
}
# Save for later performance comparison:
save(err.classification.svm, file="perf_svm.perf")
#
err.classification.svm
#7.2
#support vector machine
set.seed(1234)
gamma.value <- c(1/100,1/50,1/9,2) #possible values of gamma
rname <- c("gamma=1/100", "gamma=1/50","gamma=1/9","gamma=2")
cname <- c("value")
err.classification.svm <- matrix(0,nrow=length(gamma.value),ncol = 1,
dimnames=list(rname,cname))
for(i in 1:3){
fit.svm <- svm(class~., data=df.train,gamma=gamma.value[i],
kernel="radial")
#gamma default:  1/(data dimension), in this case 1/9
fit.svm
svm.pred <- predict(fit.svm, na.omit(df.validate))
svm.perf <- table(na.omit(df.validate)$class,
svm.pred, dnn=c("Actual", "Predicted"))
err.classification.svm[i] <- (1 - performance(svm.perf))*100
}
# Save for later performance comparison:
save(err.classification.svm, file="perf_svm.perf")
#
err.classification.svm
#7.2
#support vector machine
set.seed(1234)
gamma.value <- c(1/100,1/50,1/9,2) #possible values of gamma
rname <- c("gamma=1/100", "gamma=1/50","gamma=1/9","gamma=2")
cname <- c("value")
err.classification.svm <- matrix(0,nrow=length(gamma.value),ncol = 1,
dimnames=list(rname,cname))
for(i in 1:length(gamma.value)){
fit.svm <- svm(class~., data=df.train,gamma=gamma.value[i],
kernel="radial")
#gamma default:  1/(data dimension), in this case 1/9
fit.svm
svm.pred <- predict(fit.svm, na.omit(df.validate))
svm.perf <- table(na.omit(df.validate)$class,
svm.pred, dnn=c("Actual", "Predicted"))
err.classification.svm[i] <- (1 - performance(svm.perf))*100
}
# Save for later performance comparison:
save(err.classification.svm, file="perf_svm.perf")
#
err.classification.svm
df.validate
#7.2
#support vector machine
set.seed(1234)
gamma.value <- c(1/100,1/50,1/9,2,3) #possible values of gamma
rname <- c("gamma=1/100", "gamma=1/50","gamma=1/9","gamma=2","gamma=3")
cname <- c("value")
err.classification.svm <- matrix(0,nrow=length(gamma.value),ncol = 1,
dimnames=list(rname,cname))
for(i in 1:length(gamma.value)){
fit.svm <- svm(class~., data=df.train,gamma=gamma.value[i],
kernel="radial")
#gamma default:  1/(data dimension), in this case 1/9
fit.svm
svm.pred <- predict(fit.svm, na.omit(df.validate))
svm.perf <- table(na.omit(df.validate)$class,
svm.pred, dnn=c("Actual", "Predicted"))
err.classification.svm[i] <- (1 - performance(svm.perf))*100
}
# Save for later performance comparison:
save(err.classification.svm, file="perf_svm.perf")
err.classification.svm
fit.svm
set.seed(1234)
gamma.value <- c(1/100,1/50,1/9,2,3) #possible values of gamma
cost.value <- c(0.1,1,2)
rname <- c("gamma=1/100", "gamma=1/50","gamma=1/9","gamma=2","gamma=3")
cname <- c("cost=0.1","cost=1","cost=2")
err.classification.svm <- matrix(0,nrow=length(gamma.value),ncol = length(cost.value),
dimnames=list(rname,cname))
for(i in 1:length(gamma.value)){
for(j in 1:length(cost.value)){
fit.svm <- svm(class~., data=df.train,gamma=gamma.value[i],cost=cost.value[j],
kernel="radial")
#gamma default:  1/(data dimension), in this case 1/9
fit.svm
svm.pred <- predict(fit.svm, na.omit(df.validate))
svm.perf <- table(na.omit(df.validate)$class,
svm.pred, dnn=c("Actual", "Predicted"))
err.classification.svm[i,j] <- (1 - performance(svm.perf))*100
}
}
# Save for later performance comparison:
save(err.classification.svm, file="perf_svm.perf")
#               value
#gamma=1/100 1.442308
#gamma=1/50  1.442308
#gamma=1/9   1.442308
#gamma=2     6.730769
#
err.classification.svm
